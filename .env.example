# Inference Backend Configuration
# Copy this file to .env and fill in your credentials

# Required - Inference endpoint URL (e.g., https://api.minimax.chat/v1)
INFERENCE_ENDPOINT=

# Required - API key for authentication
INFERENCE_API_KEY=

# Required - Model identifier (e.g., MiniMax-M2.1)
INFERENCE_MODEL=

# Optional - General Configuration
# INFERENCE_MAX_RETRIES=3
# INFERENCE_RETRY_DELAY_MS=1000
# INFERENCE_TIMEOUT_SECS=120
# INFERENCE_MAX_TOKENS=4096

# Optional - Inference Parameters
# INFERENCE_TEMPERATURE=0.7     # 0.0-2.0, higher = more random
# INFERENCE_TOP_P=0.9           # 0.0-1.0, nucleus sampling threshold
# INFERENCE_TOP_K=50            # integer, limits vocabulary to top K

# Optional - Agent Configuration
# AGENT_MAX_TOOL_ROUNDS=20     # Max tool calls per request
# AGENT_INIT_TIMEOUT_SECS=120  # Init inference timeout
# AGENT_SHUTDOWN_TIMEOUT_SECS=30 # Shutdown handling timeout
# AGENT_HANDLE_TIMEOUT_SECS=300  # Request handling timeout
