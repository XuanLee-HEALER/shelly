# Inference Backend Configuration
# Copy this file to .env and fill in your credentials

# Required - Inference endpoint URL (e.g., https://api.minimax.chat/v1)
INFERENCE_ENDPOINT=

# Required - API key for authentication
INFERENCE_API_KEY=

# Required - Model identifier (e.g., MiniMax-M2.1)
INFERENCE_MODEL=

# Optional - Configuration
# INFERENCE_MAX_RETRIES=3
# INFERENCE_RETRY_DELAY_MS=1000
# INFERENCE_TIMEOUT_SECS=120
# INFERENCE_MAX_TOKENS=4096
